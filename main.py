from fastapi import FastAPI, UploadFile, File
from fastapi.responses import StreamingResponse

from src.services.audio_io import temp_audio_file
from src.services.speech_pipeline import analyze_speech_stream
from src.models.stt_whisper import get_whisperx_models

app = FastAPI(title="Speech Analysis API")

# ì „ì—­ ë³€ìˆ˜
loaded_models = None

@app.on_event("startup")
async def startup_event():
    global loaded_models
    print("â³ ëª¨ë¸ ë¡œë”© ì¤‘...")
    loaded_models = get_whisperx_models(
        model_name="small.en",
        vad_method="silero"
    )
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

@app.on_event("shutdown")
async def shutdown_event():
    global loaded_models
    loaded_models = None
    print("ğŸ›‘ ì„œë²„ ì¢…ë£Œ")

@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    if not file.filename:
        return {"error": "íŒŒì¼ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤"}
    
    # 1. íŒŒì¼ ì½ê¸° (Bytes)
    audio_bytes = await file.read()
        
    # 2. ì œë„ˆë ˆì´í„° ë˜í¼
    def stream_with_cleanup():
        with temp_audio_file(audio_bytes, suffix=".wav") as audio_path:
            
            # íŒŒì¼ ê²½ë¡œ(audio_path)ë¥¼ íŒŒì´í”„ë¼ì¸ì— ë„˜ê¹€
            for chunk in analyze_speech_stream(
                audio_path=audio_path,
                loaded_models=loaded_models,
                mode="all"
            ):
                yield chunk

    # 3. StreamingResponse ë°˜í™˜
    return StreamingResponse(
        stream_with_cleanup(), 
        media_type="application/x-ndjson"
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)